{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Learning\n",
    "\n",
    "Imbalanced data involves cases where the different classes in your dataset are not balanced. In some circumcstances this is not a problem, for example when the sample accurately represents the true popoulation. However there are specific cases where it presents a problem, in particular when it is important to accurately classify an underrepresented class. In general this is important when the cost of missclassification is high, e.g. when the true population is more balanced than the sample. Also, as in our case, detecting fraud. While fraudulent transactions are rare, they are costly when they go undetected, because credit card companies must reimburse the customer for the fraudulent spending.\n",
    "\n",
    "Imbalanced learning, then, involves techniques which are focused on overcoming the problems of imbalanced data, and accurately predicting to minimize the costs of misclassification in the true population. We examine several techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepts we can try:\n",
    " * focal loss \n",
    " * cross entropy loss (?)\n",
    " * resampling: over and undersampling.\n",
    " * SMOTE (similar to imputation)\n",
    " * different algorithms (decision trees tend to work well with imbalanced data: need to write an explaanation of why)\n",
    " * different cost function with UNEQUAL MISSLCLASSIFICATION COSTS. (is this similar to focal loss??)\n",
    " * RUSBoost (in Matlab, is there an analogue for python?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss\n",
    "Focal loss in a type of loss function desinged for convolution neural networks, modified from Cross Entropy Loss. The idea is that on successive passes, weights are decreased for observations which have already been predicted correctly. In effect, the relative weight of difficult-to-classify observations increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focal Loss\n",
    " * benefit: faster training by skipping overrepresented data ?? (https://www.analyticsvidhya.com/blog/2020/08/a-beginners-guide-to-focal-loss-in-object-detection/)\n",
    " * this approach si speciically applide to CNN (?)\n",
    " ### Cross Entropy Loss\n",
    " penaliz wrong predictions more than right predictions\n",
    " ### Unequal Costs\n",
    " In some applications costs of misclassification may differ. In our case of email fraud this is readily apparent: misclassifying an transation as fraud causes some transactional costs and inconvenience to the consumer, but misclassifying a fraudulent transaction as real can cost the consumer or the credit card company thousands of dollars. For this reason, it seems prurient to consider a case where the amount is a function of our missclassification cost.\n",
    " \n",
    " $ E[classify as fraud | not fraud ] < $$ E[classify as real | fraud] $\n",
    " \n",
    " \n",
    " ### evaluation metrics\n",
    " F1 score and others commonly mentioned.\n",
    " https://keras.io/api/metrics/classification_metrics/\n",
    " recommended: \n",
    " AUC\n",
    " \n",
    " also interesting for applied approach: total dollars lost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "#Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have\n",
    "#not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between\n",
    "#each transaction and the first transaction in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  isFraud  \n",
       "0 -0.189115  0.133558 -0.021053  149.62        0  \n",
       "1  0.125895 -0.008983  0.014724    2.69        0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66        0  \n",
       "3 -0.221929  0.062723  0.061458  123.50        0  \n",
       "4  0.502292  0.219422  0.215153   69.99        0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns = {'Class':'isFraud'}, inplace = True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['isFraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.62369e+05, 1.31640e+04, 4.02500e+03, 1.96100e+03, 9.64000e+02,\n",
       "        5.68000e+02, 3.64000e+02, 2.62000e+02, 1.23000e+02, 1.03000e+02,\n",
       "        8.50000e+01, 5.90000e+01, 4.50000e+01, 4.70000e+01, 3.80000e+01,\n",
       "        3.10000e+01, 2.20000e+01, 1.10000e+01, 1.40000e+01, 8.00000e+00,\n",
       "        7.00000e+00, 3.00000e+00, 6.00000e+00, 5.00000e+00, 1.00000e+00,\n",
       "        4.00000e+00, 2.00000e+00, 3.00000e+00, 2.00000e+00, 3.00000e+00,\n",
       "        4.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00, 2.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00]),\n",
       " array([    0.    ,   256.9116,   513.8232,   770.7348,  1027.6464,\n",
       "         1284.558 ,  1541.4696,  1798.3812,  2055.2928,  2312.2044,\n",
       "         2569.116 ,  2826.0276,  3082.9392,  3339.8508,  3596.7624,\n",
       "         3853.674 ,  4110.5856,  4367.4972,  4624.4088,  4881.3204,\n",
       "         5138.232 ,  5395.1436,  5652.0552,  5908.9668,  6165.8784,\n",
       "         6422.79  ,  6679.7016,  6936.6132,  7193.5248,  7450.4364,\n",
       "         7707.348 ,  7964.2596,  8221.1712,  8478.0828,  8734.9944,\n",
       "         8991.906 ,  9248.8176,  9505.7292,  9762.6408, 10019.5524,\n",
       "        10276.464 , 10533.3756, 10790.2872, 11047.1988, 11304.1104,\n",
       "        11561.022 , 11817.9336, 12074.8452, 12331.7568, 12588.6684,\n",
       "        12845.58  , 13102.4916, 13359.4032, 13616.3148, 13873.2264,\n",
       "        14130.138 , 14387.0496, 14643.9612, 14900.8728, 15157.7844,\n",
       "        15414.696 , 15671.6076, 15928.5192, 16185.4308, 16442.3424,\n",
       "        16699.254 , 16956.1656, 17213.0772, 17469.9888, 17726.9004,\n",
       "        17983.812 , 18240.7236, 18497.6352, 18754.5468, 19011.4584,\n",
       "        19268.37  , 19525.2816, 19782.1932, 20039.1048, 20296.0164,\n",
       "        20552.928 , 20809.8396, 21066.7512, 21323.6628, 21580.5744,\n",
       "        21837.486 , 22094.3976, 22351.3092, 22608.2208, 22865.1324,\n",
       "        23122.044 , 23378.9556, 23635.8672, 23892.7788, 24149.6904,\n",
       "        24406.602 , 24663.5136, 24920.4252, 25177.3368, 25434.2484,\n",
       "        25691.16  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df[df.isFraud == False]['Amount'], color='b', label='Real', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([230.,  27.,  14.,   5.,  12.,   8.,   9.,   4.,   5.,   2.,   3.,\n",
       "          6.,   3.,   5.,  38.,   7.,   3.,   5.,   3.,   1.,   3.,   1.,\n",
       "          1.,   0.,   4.,   2.,   5.,   1.,   1.,   2.,   0.,   1.,   1.,\n",
       "          4.,   2.,   3.,   2.,   0.,   3.,   0.,   1.,   2.,   0.,   2.,\n",
       "          4.,   5.,   0.,   1.,   2.,   1.,   3.,   2.,   0.,   0.,   0.,\n",
       "          1.,   0.,   0.,   0.,   0.,   1.,   0.,   1.,   1.,   2.,   0.,\n",
       "          0.,   1.,   0.,   1.,   0.,   0.,   2.,   1.,   1.,   0.,   0.,\n",
       "          1.,   0.,   0.,   1.,   0.,   0.,   1.,   1.,   0.,   0.,   0.,\n",
       "          0.,   2.,   0.,   1.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   3.,   3.,   1.,   0.,   0.,   0.,   0.,   1.,   1.,\n",
       "          0.,   0.,   0.,   1.,   0.,   0.,   1.,   1.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   1.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   1.,   1.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   1.]),\n",
       " array([   0.        ,    7.08623333,   14.17246667,   21.2587    ,\n",
       "          28.34493333,   35.43116667,   42.5174    ,   49.60363333,\n",
       "          56.68986667,   63.7761    ,   70.86233333,   77.94856667,\n",
       "          85.0348    ,   92.12103333,   99.20726667,  106.2935    ,\n",
       "         113.37973333,  120.46596667,  127.5522    ,  134.63843333,\n",
       "         141.72466667,  148.8109    ,  155.89713333,  162.98336667,\n",
       "         170.0696    ,  177.15583333,  184.24206667,  191.3283    ,\n",
       "         198.41453333,  205.50076667,  212.587     ,  219.67323333,\n",
       "         226.75946667,  233.8457    ,  240.93193333,  248.01816667,\n",
       "         255.1044    ,  262.19063333,  269.27686667,  276.3631    ,\n",
       "         283.44933333,  290.53556667,  297.6218    ,  304.70803333,\n",
       "         311.79426667,  318.8805    ,  325.96673333,  333.05296667,\n",
       "         340.1392    ,  347.22543333,  354.31166667,  361.3979    ,\n",
       "         368.48413333,  375.57036667,  382.6566    ,  389.74283333,\n",
       "         396.82906667,  403.9153    ,  411.00153333,  418.08776667,\n",
       "         425.174     ,  432.26023333,  439.34646667,  446.4327    ,\n",
       "         453.51893333,  460.60516667,  467.6914    ,  474.77763333,\n",
       "         481.86386667,  488.9501    ,  496.03633333,  503.12256667,\n",
       "         510.2088    ,  517.29503333,  524.38126667,  531.4675    ,\n",
       "         538.55373333,  545.63996667,  552.7262    ,  559.81243333,\n",
       "         566.89866667,  573.9849    ,  581.07113333,  588.15736667,\n",
       "         595.2436    ,  602.32983333,  609.41606667,  616.5023    ,\n",
       "         623.58853333,  630.67476667,  637.761     ,  644.84723333,\n",
       "         651.93346667,  659.0197    ,  666.10593333,  673.19216667,\n",
       "         680.2784    ,  687.36463333,  694.45086667,  701.5371    ,\n",
       "         708.62333333,  715.70956667,  722.7958    ,  729.88203333,\n",
       "         736.96826667,  744.0545    ,  751.14073333,  758.22696667,\n",
       "         765.3132    ,  772.39943333,  779.48566667,  786.5719    ,\n",
       "         793.65813333,  800.74436667,  807.8306    ,  814.91683333,\n",
       "         822.00306667,  829.0893    ,  836.17553333,  843.26176667,\n",
       "         850.348     ,  857.43423333,  864.52046667,  871.6067    ,\n",
       "         878.69293333,  885.77916667,  892.8654    ,  899.95163333,\n",
       "         907.03786667,  914.1241    ,  921.21033333,  928.29656667,\n",
       "         935.3828    ,  942.46903333,  949.55526667,  956.6415    ,\n",
       "         963.72773333,  970.81396667,  977.9002    ,  984.98643333,\n",
       "         992.07266667,  999.1589    , 1006.24513333, 1013.33136667,\n",
       "        1020.4176    , 1027.50383333, 1034.59006667, 1041.6763    ,\n",
       "        1048.76253333, 1055.84876667, 1062.935     , 1070.02123333,\n",
       "        1077.10746667, 1084.1937    , 1091.27993333, 1098.36616667,\n",
       "        1105.4524    , 1112.53863333, 1119.62486667, 1126.7111    ,\n",
       "        1133.79733333, 1140.88356667, 1147.9698    , 1155.05603333,\n",
       "        1162.14226667, 1169.2285    , 1176.31473333, 1183.40096667,\n",
       "        1190.4872    , 1197.57343333, 1204.65966667, 1211.7459    ,\n",
       "        1218.83213333, 1225.91836667, 1233.0046    , 1240.09083333,\n",
       "        1247.17706667, 1254.2633    , 1261.34953333, 1268.43576667,\n",
       "        1275.522     , 1282.60823333, 1289.69446667, 1296.7807    ,\n",
       "        1303.86693333, 1310.95316667, 1318.0394    , 1325.12563333,\n",
       "        1332.21186667, 1339.2981    , 1346.38433333, 1353.47056667,\n",
       "        1360.5568    , 1367.64303333, 1374.72926667, 1381.8155    ,\n",
       "        1388.90173333, 1395.98796667, 1403.0742    , 1410.16043333,\n",
       "        1417.24666667, 1424.3329    , 1431.41913333, 1438.50536667,\n",
       "        1445.5916    , 1452.67783333, 1459.76406667, 1466.8503    ,\n",
       "        1473.93653333, 1481.02276667, 1488.109     , 1495.19523333,\n",
       "        1502.28146667, 1509.3677    , 1516.45393333, 1523.54016667,\n",
       "        1530.6264    , 1537.71263333, 1544.79886667, 1551.8851    ,\n",
       "        1558.97133333, 1566.05756667, 1573.1438    , 1580.23003333,\n",
       "        1587.31626667, 1594.4025    , 1601.48873333, 1608.57496667,\n",
       "        1615.6612    , 1622.74743333, 1629.83366667, 1636.9199    ,\n",
       "        1644.00613333, 1651.09236667, 1658.1786    , 1665.26483333,\n",
       "        1672.35106667, 1679.4373    , 1686.52353333, 1693.60976667,\n",
       "        1700.696     , 1707.78223333, 1714.86846667, 1721.9547    ,\n",
       "        1729.04093333, 1736.12716667, 1743.2134    , 1750.29963333,\n",
       "        1757.38586667, 1764.4721    , 1771.55833333, 1778.64456667,\n",
       "        1785.7308    , 1792.81703333, 1799.90326667, 1806.9895    ,\n",
       "        1814.07573333, 1821.16196667, 1828.2482    , 1835.33443333,\n",
       "        1842.42066667, 1849.5069    , 1856.59313333, 1863.67936667,\n",
       "        1870.7656    , 1877.85183333, 1884.93806667, 1892.0243    ,\n",
       "        1899.11053333, 1906.19676667, 1913.283     , 1920.36923333,\n",
       "        1927.45546667, 1934.5417    , 1941.62793333, 1948.71416667,\n",
       "        1955.8004    , 1962.88663333, 1969.97286667, 1977.0591    ,\n",
       "        1984.14533333, 1991.23156667, 1998.3178    , 2005.40403333,\n",
       "        2012.49026667, 2019.5765    , 2026.66273333, 2033.74896667,\n",
       "        2040.8352    , 2047.92143333, 2055.00766667, 2062.0939    ,\n",
       "        2069.18013333, 2076.26636667, 2083.3526    , 2090.43883333,\n",
       "        2097.52506667, 2104.6113    , 2111.69753333, 2118.78376667,\n",
       "        2125.87      ]),\n",
       " <BarContainer object of 300 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANW0lEQVR4nO3dT4yc9X3H8fenkHBIkLBr17IA1STyxT2UWCuKVBRRIfHvYnJB5FAsiuQeQEqk9kCaQzimlZJKSC2So6CYKoUiJQgOtIlrRUI9QLKOiDFQgkNAYBnslIhQRUoL+fYwj9PB7Hp3dna8nq/fL2k1z/6eZ3Z++2PmveNndodUFZKkXn5voycgSVp/xl2SGjLuktSQcZekhoy7JDV08UZPAGDLli21Y8eOjZ6GJM2Vw4cP/6Kqti6177yI+44dO1hcXNzoaUjSXEny+nL7PC0jSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDc1/3JONnoEknXfmP+6SpI8w7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWpoxbgnuTLJD5K8mOSFJF8YxjcnOZjkleFy0zCeJA8kOZbkSJLds/4mJEkftppn7u8Df1VVu4BrgXuS7ALuAw5V1U7g0PA5wC3AzuFjH/Dgus9aknRWK8a9qk5U1Y+H7feAl4DLgT3AgeGwA8Btw/Ye4OEaeQa4LMn29Z64JGl5E51zT7ID+AzwLLCtqk4Mu94Ctg3blwNvjF3tzWHszK+1L8liksVTp05NOm9J0lmsOu5JPgl8B/hiVf1qfF9VFVCT3HBV7a+qhapa2Lp16yRXlSStYFVxT/IxRmH/dlV9dxh++/TpluHy5DB+HLhy7OpXDGOSpHNkNb8tE+CbwEtV9fWxXU8Ce4ftvcATY+N3Dr81cy3w7tjpG0nSOXDxKo75U+DPgeeTPDeM/Q3wVeCxJHcDrwO3D/ueAm4FjgG/Bu5azwlLkla2Ytyr6j+ALLP7hiWOL+CeKeclSZqCf6EqSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8ZdkhpaMe5JHkpyMsnRsbH7kxxP8tzwcevYvi8lOZbk5SQ3zWrikqTlreaZ+7eAm5cY//uqunr4eAogyS7gDuCPhuv8Y5KL1muykqTVWTHuVfU08M4qv94e4NGq+k1V/Rw4BlwzxfwkSWswzTn3e5McGU7bbBrGLgfeGDvmzWHsI5LsS7KYZPHUqVNTTEOSdKa1xv1B4NPA1cAJ4GuTfoGq2l9VC1W1sHXr1jVOQ5K0lDXFvarerqoPquq3wDf4/1Mvx4Erxw69YhiTJJ1Da4p7ku1jn34OOP2bNE8CdyS5JMlVwE7gh9NNUZI0qYtXOiDJI8D1wJYkbwJfAa5PcjVQwGvAXwJU1QtJHgNeBN4H7qmqD2Yyc0nSslJVGz0HFhYWanFxcW1XTuA8+B4k6VxLcriqFpba51+oSlJDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGVox7koeSnExydGxsc5KDSV4ZLjcN40nyQJJjSY4k2T3LyUuSlraaZ+7fAm4+Y+w+4FBV7QQODZ8D3ALsHD72AQ+uzzQlSZNYMe5V9TTwzhnDe4ADw/YB4Lax8Ydr5BngsiTb12mukqRVWus5921VdWLYfgvYNmxfDrwxdtybw9hHJNmXZDHJ4qlTp9Y4DUnSUqZ+QbWqCqg1XG9/VS1U1cLWrVunnYYkacxa4/726dMtw+XJYfw4cOXYcVcMY5Kkc2itcX8S2Dts7wWeGBu/c/itmWuBd8dO30iSzpGLVzogySPA9cCWJG8CXwG+CjyW5G7gdeD24fCngFuBY8CvgbtmMGdJ0gpWjHtVfX6ZXTcscWwB90w7KUnSdPwLVUlqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLU0MXTXDnJa8B7wAfA+1W1kGQz8C/ADuA14Paq+uV005QkTWI9nrn/WVVdXVULw+f3AYeqaidwaPhcknQOzeK0zB7gwLB9ALhtBrchSTqLaeNewPeTHE6ybxjbVlUnhu23gG1LXTHJviSLSRZPnTo15TQkSeOmOucOXFdVx5P8AXAwyX+O76yqSlJLXbGq9gP7ARYWFpY8RpK0NlM9c6+q48PlSeBx4Brg7STbAYbLk9NOUpI0mTXHPcknklx6ehu4ETgKPAnsHQ7bCzwx7SQlSZOZ5rTMNuDxJKe/zj9X1b8l+RHwWJK7gdeB26efpiRpEmuOe1W9CvzxEuP/BdwwzaQkSdPxL1QlqSHjLkkNGXdJasi4S1JDxl2SGrqw4z76NU5JaufCjrskNWXcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIZ6xN0/RpKkD+kRd0nShxh3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDfeLu+8tI0u/0ibsk6Xf6xd1n8JLUMO6SJOMuSR31jrunaCRdoHrGPVl92P0BIKmhnnE/G2Mu6QLQK+7LhXup8TPHVhP99fzB4A8ZSTPUK+5LWY+Irnf4DbukGZtZ3JPcnOTlJMeS3Der25nI6agu96x9uf1ruY21fJ1u0Z/ktQ9J62omcU9yEfAPwC3ALuDzSXbN4rYmmNT6Xv9sp3rWum+5/ZPObdL963U7ks4bs3rmfg1wrKperar/AR4F9szottbXeISXC/GZMZ4mriv9a2GlHxQr/SvkzHku94Nkku9p0h9Gq1nHSecwyW1Nc9x6X3c9v85K/x3W419O8/QDfZ7metoM53zxjL7u5cAbY5+/CfzJ+AFJ9gH7hk//O8nLa7ytLcAv1njdla02csvtO9sDcLVBn/QF4Q/f9kfXZzWBX+l21yPwq7nN2Qd+bfefeQn8dLcxWpt5iua5nev6tGe6Of/hcjtmFfcVVdV+YP+0XyfJYlUtrMOUWnJ9zs71WZ5rc3bn+/rM6rTMceDKsc+vGMYkSefArOL+I2BnkquSfBy4A3hyRrclSTrDTE7LVNX7Se4FvgdcBDxUVS/M4rZYh1M7zbk+Z+f6LM+1Obvzen1SVRs9B0nSOuv/F6qSdAEy7pLU0FzH/bx8i4NzLMlrSZ5P8lySxWFsc5KDSV4ZLjcN40nywLBeR5Ls3tjZr78kDyU5meTo2NjE65Fk73D8K0n2bsT3MgvLrM/9SY4P96Hnktw6tu9Lw/q8nOSmsfF2j70kVyb5QZIXk7yQ5AvD+Hzef6pqLj8YvVD7M+BTwMeBnwC7NnpeG7AOrwFbzhj7O+C+Yfs+4G+H7VuBfwUCXAs8u9Hzn8F6fBbYDRxd63oAm4FXh8tNw/amjf7eZrg+9wN/vcSxu4bH1SXAVcPj7aKujz1gO7B72L4U+OmwBnN5/5nnZ+7z+xYHs7cHODBsHwBuGxt/uEaeAS5Lsn0D5jczVfU08M4Zw5Oux03Awap6p6p+CRwEbp755M+BZdZnOXuAR6vqN1X1c+AYo8ddy8deVZ2oqh8P2+8BLzH6a/u5vP/Mc9yXeouDyzdoLhupgO8nOTy8pQPAtqo6MWy/BWwbti/UNZt0PS7Edbp3OLXw0OnTDlzA65NkB/AZ4Fnm9P4zz3HXyHVVtZvRO3Dek+Sz4ztr9O9Ef9914Hos6UHg08DVwAngaxs6mw2W5JPAd4AvVtWvxvfN0/1nnuPuWxwAVXV8uDwJPM7on8xvnz7dMlyeHA6/UNds0vW4oNapqt6uqg+q6rfANxjdh+ACXJ8kH2MU9m9X1XeH4bm8/8xz3C/4tzhI8okkl57eBm4EjjJah9Ov0O8Fnhi2nwTuHF7lvxZ4d+yfm51Nuh7fA25Msmk4RXHjMNbSGa+7fI7RfQhG63NHkkuSXAXsBH5I08dekgDfBF6qqq+P7ZrP+89Gv0I9zQejV6t/yuiV+y9v9Hw24Pv/FKPfVPgJ8MLpNQB+HzgEvAL8O7B5GA+j/4nKz4DngYWN/h5msCaPMDq18L+MznXevZb1AP6C0QuIx4C7Nvr7mvH6/NPw/R9hFKztY8d/eVifl4FbxsbbPfaA6xidcjkCPDd83Dqv9x/ffkCSGprn0zKSpGUYd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNfR/j89frYErDR4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[df.isFraud == True]['Amount'], color='r', label='Fraud', bins=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(data):\n",
    "    return (data - np.mean(data, axis=0)) / np.std(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "X, y = df.iloc[:,:-1], df.iloc[:, -1]\n",
    "y = keras.utils.to_categorical(y, num_classes=2)\n",
    "\n",
    "X_orig = X\n",
    "X = norm(X) #normalize the data to N(0,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### build keras neural network models [BE MORE SPECIFIC! ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "mod_focal = Sequential()\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]\n",
    "\n",
    "mod_focal.add(Dense(10, input_dim=input_dim, activation='relu', name='input'))\n",
    "mod_focal.add(Dense(20, activation='relu', name='fc1'))\n",
    "mod_focal.add(Dense(10, activation='relu', name='fc2'))\n",
    "mod_focal.add(Dense(nb_classes, activation='softmax', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_ce_acc = tf.keras.models.clone_model(mod_focal)\n",
    "mod_ce_acc.compile(loss='binary_crossentropy',\n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "                     \n",
    "mod_ce_rec = tf.keras.models.clone_model(mod_focal)\n",
    "mod_ce_rec.compile(loss='binary_crossentropy',\n",
    "              optimizer='nadam',\n",
    "              metrics=['recall'])\n",
    "              \n",
    "mod_dectree = tf.keras.models.clone_model(mod_focal)\n",
    "mod_unequal = tf.keras.models.clone_model(mod_focal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focal loss method, source: github link\n",
    "\n",
    "class FocalLoss(keras.losses.Loss):\n",
    "    def __init__(self, gamma=2., alpha=4.,\n",
    "                 reduction=keras.losses.Reduction.AUTO, name='focal_loss'):\n",
    "        \"\"\"Focal loss for multi-classification\n",
    "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
    "        Notice: y_pred is probability after softmax\n",
    "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
    "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
    "        Focal Loss for Dense Object Detection\n",
    "        https://arxiv.org/abs/1708.02002\n",
    "\n",
    "        Keyword Arguments:\n",
    "            gamma {float} -- (default: {2.0})\n",
    "            alpha {float} -- (default: {4.0})\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__(reduction=reduction,\n",
    "                                        name=name)\n",
    "        self.gamma = float(gamma)\n",
    "        self.alpha = float(alpha)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
    "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
    "\n",
    "        Returns:\n",
    "            [tensor] -- loss.\n",
    "        \"\"\"\n",
    "        epsilon = 1.e-9\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "\n",
    "        model_out = tf.add(y_pred, epsilon)\n",
    "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
    "        weight = tf.multiply(y_true, tf.pow(\n",
    "            tf.subtract(1., model_out), self.gamma))\n",
    "        fl = tf.multiply(self.alpha, tf.multiply(weight, ce))\n",
    "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
    "        return tf.reduce_mean(reduced_fl)\n",
    "\n",
    "\n",
    "mod_focal.compile(loss=FocalLoss(alpha=1),\n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Dense)                (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 762\n",
      "Trainable params: 762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9993\n",
      "Epoch 2/3\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 0.9994\n",
      "Epoch 3/3\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 9.4560e-04 - accuracy: 0.9994\n",
      "Epoch 1/3\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.1267 - accuracy: 0.9891\n",
      "Epoch 2/3\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9982\n",
      "Epoch 3/3\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9982\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:759 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:388 update_state\n        self.build(y_pred, y_true)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:318 build\n        self._metrics = nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1135 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1234 map_structure_with_tuple_paths_up_to\n        results = [func(*args, **kwargs) for args in zip(flat_path_list,\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1234 <listcomp>\n        results = [func(*args, **kwargs) for args in zip(flat_path_list,\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1137 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:419 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:419 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:438 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:3483 get\n        return deserialize(str(identifier))\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:3439 deserialize\n        return deserialize_keras_object(\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:377 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: recall\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f12ed0df4a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmod_focal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmod_ce_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmod_ce_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:759 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:388 update_state\n        self.build(y_pred, y_true)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:318 build\n        self._metrics = nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1135 map_structure_up_to\n        return map_structure_with_tuple_paths_up_to(\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1234 map_structure_with_tuple_paths_up_to\n        results = [func(*args, **kwargs) for args in zip(flat_path_list,\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1234 <listcomp>\n        results = [func(*args, **kwargs) for args in zip(flat_path_list,\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1137 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:419 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:419 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:438 _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:3483 get\n        return deserialize(str(identifier))\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py:3439 deserialize\n        return deserialize_keras_object(\n    /usr/local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:377 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: recall\n"
     ]
    }
   ],
   "source": [
    "mod_focal.summary()\n",
    "mod_focal.fit(X_train, y_train, epochs=3, batch_size=1000) #fit model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 2/3\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 3/3\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1545bd100>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_ce_acc.fit(X_train, y_train, epochs=3, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d0264ea7a4f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod_ce_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "mod_ce_rec.fit(X_train, y_train, epochs=3, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### evaluate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mod_focal.evaluate(X_test, y_test, batch_size=1000) #evaluate fit using ??? method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: instead of confusion matrix, use the ML things they tend to use: accuracy, and th eother two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2)\n",
    "predictions = mod_focal.predict(X_test, batch_size=1000)\n",
    "\n",
    "LABELS = ['Real','Fraud'] \n",
    "\n",
    "max_test = np.argmax(y_test, axis=1)\n",
    "max_predictions = np.argmax(predictions, axis=1)\n",
    "confusion_matrix = metrics.confusion_matrix(max_test, max_predictions)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\", annot_kws={\"size\": 20});\n",
    "plt.title(\"Confusion matrix\", fontsize=20)\n",
    "plt.ylabel('True label', fontsize=20)\n",
    "plt.xlabel('Predicted label', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = confusion_matrix.view()\n",
    "error_count = values.sum() - np.trace(values)\n",
    "error_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new metric: amount of money lost by company due to fraud. (assuming they reimburse all fraud cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of fraud cases categorizes as real -> get the amount of money\n",
    "X_temp = X_orig.iloc[X_test.index]['Amount']\n",
    "total_monetary_loss = sum(X_temp[(max_test != max_predictions) & (max_test == 1)])\n",
    "print(\"total monetary loss: \" + str(total_monetary_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
